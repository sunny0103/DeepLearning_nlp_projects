{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "authorship_tag": "ABX9TyOASx6JLcdoxh3USdvsUVJE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sunny0103/DeepLearning_nlp_projects/blob/main/nlg_practice%20/Wikitext_NLG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VJJW-t2YGQlz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24d788be-0cbb-4e61-b132-2226d6d8b2b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.34.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.12.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.1)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.1.0+cu118)\n",
            "Requirement already satisfied: accelerate>=0.20.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers[torch]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir my_data\n",
        "!curl -c ./cookie -s -L \"https://drive.google.com/uc?export=download&id=1zib1GI8Q5wV08TgYBa2GagqNh4jyfXZz\" > /dev/null\n",
        "!curl -Lb ./cookie \"https://drive.google.com/uc?export=download&confirm=`awk '/download/ {print $NF}' ./cookie`&id=1zib1GI8Q5wV08TgYBa2GagqNh4jyfXZz\" -o my_data/wiki_small.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xs4ML8ZBLuA5",
        "outputId": "e248e5ef-531f-4085-e048-64b9035ebd80"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘my_data’: File exists\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 1323k  100 1323k    0     0  1731k      0 --:--:-- --:--:-- --:--:-- 1731k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/my_data/wiki_small.txt'"
      ],
      "metadata": {
        "id": "LVqzkgZoPtuk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "import time\n",
        "import warnings\n",
        "from typing import Dict, List, Optional\n",
        "\n",
        "import torch\n",
        "from torch.utils.data.dataset import Dataset\n",
        "\n",
        "from tokenizers import SentencePieceBPETokenizer\n",
        "from tokenizers.normalizers import BertNormalizer\n",
        "\n",
        "from transformers import (GPT2Config,\n",
        "                          GPT2LMHeadModel,\n",
        "                          DataCollatorForLanguageModeling,\n",
        "                          Trainer,\n",
        "                          TrainingArguments)\n",
        "from transformers.tokenization_utils import PreTrainedTokenizer\n",
        "from transformers.utils import logging\n",
        "\n",
        "from filelock import FileLock\n"
      ],
      "metadata": {
        "id": "vM7ua6u8IZab"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = SentencePieceBPETokenizer()"
      ],
      "metadata": {
        "id": "UBN7mvzqQGEC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer._tokenizer.normalizer = BertNormalizer(\n",
        "    clean_text = True,\n",
        "    handle_chinese_chars=False,\n",
        "    lowercase=False\n",
        ")"
      ],
      "metadata": {
        "id": "yVvKaVzoRLng"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train tokenizer"
      ],
      "metadata": {
        "id": "gTfcy0JdSThv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.train(\n",
        "    path,\n",
        "    vocab_size= 10000,\n",
        "    special_tokens=[\"<s>\", \"<pad>\", \"</s>\", \"<unk>\"],\n",
        ")"
      ],
      "metadata": {
        "id": "j5LShuM6Rutl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text=\"문장생성 실습을 위한 샘플 텍스트 입니다.\""
      ],
      "metadata": {
        "id": "5_DCfBIZSzya"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.encode(sample_text))\n",
        "print(tokenizer.encode(sample_text).ids)\n",
        "print(tokenizer.encode(sample_text).tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLpUvVjJS94h",
        "outputId": "33e7eafe-b459-4475-d2a7-73ff148545af"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding(num_tokens=14, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
            "[1073, 722, 544, 555, 1083, 588, 701, 1553, 104, 3, 930, 2983, 1203, 3234]\n",
            "['▁문', '장', '생', '성', '▁실', '습', '을', '▁위한', '▁', '<unk>', '플', '▁텍스트', '▁입', '니다.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(tokenizer.encode(sample_text).ids, skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0Gv7RkaTcwK",
        "outputId": "7b987c97-6677-44f2-e61e-8bd4462fa241"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문장생성 실습을 위한 플 텍스트 입니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save trained tokenizer**"
      ],
      "metadata": {
        "id": "8ipQpuPRSpkj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.save_model(\".\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79PizrHBSSjG",
        "outputId": "e5ae2ec9-4d99-4854-8a23-ea1957e678ad"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['./vocab.json', './merges.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = SentencePieceBPETokenizer.from_file(vocab_filename=\"vocab.json\", merges_filename=\"merges.txt\")"
      ],
      "metadata": {
        "id": "k0OdFUTET-MK"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.add_special_tokens([\"<s>\", \"</s>\", \"<unk>\", \"<pad>\"])"
      ],
      "metadata": {
        "id": "XZ3D0dD8UIAf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d095cfcd-31e9-4a99-fc5b-97d9829ed0f1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.bos_token_id = tokenizer.token_to_id(\"<bos>\")\n",
        "tokenizer.eos_token_id = tokenizer.token_to_id(\"<eos>\")\n",
        "tokenizer.unk_token_id = tokenizer.token_to_id(\"<unk>\")\n",
        "tokenizer.pad_token_id = tokenizer.token_to_id(\"<pad>\")"
      ],
      "metadata": {
        "id": "vjmJBiWUHViz"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_add_text = \"<s>\" + sample_text +\"</s>\""
      ],
      "metadata": {
        "id": "0cVFo1txIAaz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.encode(sample_add_text))\n",
        "print(tokenizer.encode(sample_add_text).ids)\n",
        "print(tokenizer.encode(sample_add_text).tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swaQleU9IVYm",
        "outputId": "973e11f6-b70b-4e00-9ef4-aa565a467ff2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding(num_tokens=16, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
            "[0, 1073, 722, 544, 555, 1083, 588, 701, 1553, 104, 3, 930, 2983, 1203, 3234, 2]\n",
            "['<s>', '▁문', '장', '생', '성', '▁실', '습', '을', '▁위한', '▁', '<unk>', '플', '▁텍스트', '▁입', '니다.', '</s>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = GPT2Config(\n",
        "    vocab_size = tokenizer.get_vocab_size(),\n",
        "    bos_token_id = tokenizer.token_to_id(\"<s>\"),\n",
        "    eos_token_id = tokenizer.token_to_id(\"</s>\")\n",
        ")\n",
        "config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MWUhfRBIyh2",
        "outputId": "0e9cf5fc-c407-45b3-8798-408d2a07af74"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2Config {\n",
              "  \"activation_function\": \"gelu_new\",\n",
              "  \"attn_pdrop\": 0.1,\n",
              "  \"bos_token_id\": 0,\n",
              "  \"embd_pdrop\": 0.1,\n",
              "  \"eos_token_id\": 2,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"layer_norm_epsilon\": 1e-05,\n",
              "  \"model_type\": \"gpt2\",\n",
              "  \"n_embd\": 768,\n",
              "  \"n_head\": 12,\n",
              "  \"n_inner\": null,\n",
              "  \"n_layer\": 12,\n",
              "  \"n_positions\": 1024,\n",
              "  \"reorder_and_upcast_attn\": false,\n",
              "  \"resid_pdrop\": 0.1,\n",
              "  \"scale_attn_by_inverse_layer_idx\": false,\n",
              "  \"scale_attn_weights\": true,\n",
              "  \"summary_activation\": null,\n",
              "  \"summary_first_dropout\": 0.1,\n",
              "  \"summary_proj_to_labels\": true,\n",
              "  \"summary_type\": \"cls_index\",\n",
              "  \"summary_use_proj\": true,\n",
              "  \"transformers_version\": \"4.34.1\",\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 10000\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPT2LMHeadModel(config)"
      ],
      "metadata": {
        "id": "_MvstHMVKn13"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.num_parameters()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sytlqn8dK387",
        "outputId": "49ed6a54-5124-4400-ebe1-ddb2d33081bf"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "93522432"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTDataset(Dataset):\n",
        "  def __init__(self, tokenzier, file_path, block_size):\n",
        "    block_size = block_size - tokenizer.num_special_tokens_to_add(is_pair=False)\n",
        "    text =\"\"\n",
        "    with open (path, encoding=\"utf-8\") as f:\n",
        "      lines = f.readlines()\n",
        "      for line in lines:\n",
        "        line = line.strip()\n",
        "        line = \"<s>\"+line+\"</s>\"\n",
        "        text += line\n",
        "\n",
        "    tokenzied_text = tokenizer.encode(text).ids\n",
        "\n",
        "    self.dataset = []\n",
        "    for i in range(0, len(tokenzied_text)-block_size+1, block_size):\n",
        "      self.dataset.append(tokenzied_text[i:i+block_size])\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "      return torch.tensor(self.dataset[index],dtype=torch.long)\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.dataset)\n"
      ],
      "metadata": {
        "id": "xA36pSg9REd_"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = GPTDataset(\n",
        "    tokenzier = tokenizer,\n",
        "    file_path = path,\n",
        "    block_size = 128\n",
        ")"
      ],
      "metadata": {
        "id": "1eVg06upVMZV"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnyjqAf_Va2G",
        "outputId": "0b1eec93-0ba1-41a0-eb9c-315052004308"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([   0, 3997, 3546, 8404,  462,    4, 5481, 9527, 1798, 1890, 2297, 1262,\n",
              "        9625, 2679, 1188, 2174,    2,    0, 5709, 5481,  254, 6466,  749, 3426,\n",
              "         873, 1556,  679,  895, 1627, 9222,  585, 3621, 1010, 3303,    2,    0,\n",
              "        6466, 7418, 2305,  402, 2217, 1074,    2,    0, 1013, 1107, 3716,  645,\n",
              "        8574, 1024,  940,   92, 7323,  370,   92,  720, 9294,  704, 1651,  452,\n",
              "        3167, 1032, 1074,    2,    0, 6343, 1262, 3716, 1009, 2931, 1176,  913,\n",
              "        2037, 1171, 3228,  843,   92,  438,  974, 1486, 1017,    3, 1323, 3914,\n",
              "        2095, 1042,    2,    0, 1383, 2068, 2225, 1095,  325,  843, 1823,  505,\n",
              "           4, 1240, 7698,    2,    0, 3897, 6466, 1053, 1077,  685, 2318, 4649,\n",
              "        5204, 5672, 1013, 1759,  115, 2742, 3003,  104,  654, 2283, 9764, 1192,\n",
              "        1796, 2449, 2546, 9937, 6466, 1053, 1037,  532])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
      ],
      "metadata": {
        "id": "6TuX6VRAVeiq"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir = \"gpt2_model_output\",\n",
        "    num_train_epochs=120,\n",
        "    per_device_train_batch_size=64,\n",
        "    save_total_limit=2,\n",
        "    logging_steps=600\n",
        "\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model = model,\n",
        "    args = training_args,\n",
        "    data_collator= collator,\n",
        "    train_dataset = dataset\n",
        ")"
      ],
      "metadata": {
        "id": "cKN8lT0wWAYj"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "tf2Hj5oNXv6d",
        "outputId": "8dce581c-3eaf-4621-b818-a61b8bc3d92b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3600' max='3600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3600/3600 29:52, Epoch 120/120]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.513700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>4.379800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>2.839700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>1.772800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>1.145400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.850800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3600, training_loss=2.917037319607205, metrics={'train_runtime': 1794.1045, 'train_samples_per_second': 126.882, 'train_steps_per_second': 2.007, 'total_flos': 1.487012954112e+16, 'train_loss': 2.917037319607205, 'epoch': 120.0})"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model()"
      ],
      "metadata": {
        "id": "X_jNB3oBYy_C"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "vjBtCNl6hYtl"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NNoK4J5hi1m",
        "outputId": "a37b7aaf-d1c1-4553-debc-262d93f0f9af"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7c674879d310>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = torch.tensor(tokenizer.encode(\"<s> 문장생성 실습을\", add_special_tokens=True).ids).unsqueeze(0).to('cuda')"
      ],
      "metadata": {
        "id": "rlz3jHRBhl2x"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# random sampling\n",
        "output_sentences = model.generate(input_ids = input_ids,\n",
        "                                  do_sample = True,\n",
        "                                  max_length=50,\n",
        "                                  num_return_sequences=3\n",
        "                                  )\n",
        "\n",
        "for generated_sentence in output_sentences:\n",
        "  generated_sentence = generated_sentence.tolist()\n",
        "  print(\"generated_sentence:{}\".format(tokenizer.decode(generated_sentence, skip_special_tokens=True)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRFujSZJiEDp",
        "outputId": "0bb85387-fae3-4e67-e33a-1d2a9cf35058"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated_sentence:문장생성 실습을 차지하던 새천년민주당 등 여러 화식을 받았다.\n",
            "generated_sentence:문장생성 실습을 거쳐 사용하며 영향라 회사와 2시였다.\n",
            "generated_sentence:문장생성 실습을 받았다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#top-k sampling\n",
        "output_sentences = model.generate(input_ids = input_ids,\n",
        "                                  do_sample = True,\n",
        "                                  max_length=50,\n",
        "                                  top_k=50,\n",
        "                                  num_return_sequences=3\n",
        "                                  )\n",
        "\n",
        "for generated_sentence in output_sentences:\n",
        "  generated_sentence = generated_sentence.tolist()\n",
        "  print(\"generated_sentence:{}\".format(tokenizer.decode(generated_sentence, skip_special_tokens=True)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6tJOpCji047",
        "outputId": "2cc54eed-5b3b-46e8-dfa4-bd60c3e0fc28"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated_sentence:문장생성 실습을 두고 복아 문화 비정 및 이에 지그디기의 경영리환한 중국 대륙아 최예, 사시자라고 부른다.\n",
            "generated_sentence:문장생성 실습을 시도하였으나 임시정부의 웹취 시장으로 용동계과는 이어져고등 이루어져 있다.\n",
            "generated_sentence:문장생성 실습을 열어었고, 선박이다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# top-p sampling\n",
        "output_sentences = model.generate(input_ids = input_ids,\n",
        "                                  do_sample = True,\n",
        "                                  max_length=50,\n",
        "                                  top_p=0.92,\n",
        "                                  top_k=0,\n",
        "                                  num_return_sequences=3\n",
        "                                  )\n",
        "\n",
        "for generated_sentence in output_sentences:\n",
        "  generated_sentence = generated_sentence.tolist()\n",
        "  print(\"generated_sentence:{}\".format(tokenizer.decode(generated_sentence, skip_special_tokens=True)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPbKPfe5jJOo",
        "outputId": "a8ba5d97-d86f-4f06-f89e-c952b9220b10"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated_sentence:문장생성 실습을 계기로 3월회국, 문왔다고 하면, 북동 소형이었으나 단체 핵리가메리사는 경쟁 총도는 양 1년을였다.\n",
            "generated_sentence:문장생성 실습을 이용한사이트 의무총치편F갔다.\n",
            "generated_sentence:문장생성 실습을 동원해 폴링의듬고 아이 생활 체결하여 경장에 취임하였다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-50lkAljjQnO"
      },
      "execution_count": 32,
      "outputs": []
    }
  ]
}